{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "    - Find a way to import modules using (relative) path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fastai'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-82f5a6afa705>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfastai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimports\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfastai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfastai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_learner\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfastai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fastai'"
     ]
    }
   ],
   "source": [
    "from fastai.imports import *\n",
    "\n",
    "from fastai.transforms import *\n",
    "from fastai.conv_learner import *\n",
    "from fastai.model import *\n",
    "from fastai.dataset import *\n",
    "from fastai.sgdr import *\n",
    "from fastai.plots import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fastai'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-8cd4ba28ae9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfastai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fastai'"
     ]
    }
   ],
   "source": [
    "from fastai import imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastai = \"../../FastAi/fastai\"\n",
    "fastai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['torch_imports.py',\n",
       " 'losses.py',\n",
       " '.gitignore',\n",
       " 'set_spawn.py',\n",
       " 'models',\n",
       " 'rnn_reg.py',\n",
       " 'layers.py',\n",
       " 'sgdr.py',\n",
       " 'adaptive_softmax.py',\n",
       " 'structured.py',\n",
       " 'nlp.py',\n",
       " 'text.py',\n",
       " 'utils.py',\n",
       " 'images',\n",
       " 'model.py',\n",
       " 'learner.py',\n",
       " 'layer_optimizer.py',\n",
       " 'rnn_train.py',\n",
       " 'transforms.py',\n",
       " 'initializers.py',\n",
       " 'plots.py',\n",
       " 'core.py',\n",
       " 'metrics.py',\n",
       " '__init__.py',\n",
       " 'dataset.py',\n",
       " 'dataloader.py',\n",
       " 'column_data.py',\n",
       " 'conv_learner.py',\n",
       " 'imports.py',\n",
       " 'io.py',\n",
       " 'lm_rnn.py']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(fastai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/home/sindre/anaconda3/envs/fastai/lib/python36.zip', '/home/sindre/anaconda3/envs/fastai/lib/python3.6', '/home/sindre/anaconda3/envs/fastai/lib/python3.6/lib-dynload', '/home/sindre/anaconda3/envs/fastai/lib/python3.6/site-packages', '/home/sindre/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/extensions', '/home/sindre/.ipython', './FastAi/fastai', '../../FastAi/fastai']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../../FastAi/fastai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "> Download the pictures in notebook <br>\n",
    ">> Use Keras folder structure with \"train\", \"valid\", \"train/class1\", ... \n",
    "<br> <br>\n",
    ">> Rename the pictures <cr>\n",
    "    \n",
    "> Refactor the methods "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading the images\n",
    "\n",
    "Downloading the images using a program from https://github.com/hardikvasa/google-images-download and running it through bash scripting locally in the notebook. More possible configurations, such as multiple searchwords, different combinations, etc., but this is enough for now. \n",
    "\n",
    "To run this method:\n",
    "> Using pip\n",
    "> <div class=\"alert alert-block alert-info\">\n",
    "\\$ pip install google_images_download\n",
    "</div> <br>\n",
    "> Manually using CLI\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "> \\$ git clone https://github.com/hardikvasa/google-images-download.git <br>\n",
    "> \\$ cd google-images-download && sudo python setup.py install\n",
    "</div> <br>\n",
    "> Manually using UI\n",
    "> <div class=\"alert alert-block alert-info\">\n",
    "> Go to the repo on github ==> Click on *Clone or Download* ==> Click on *Download ZIP* and save it on your local disk. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The specified searchword will be a class, which in this case will be *female* and *male* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_pictures(searchword, form=\"jpg\", lim=100, directory=\"data/\"):\n",
    "    ! googleimagesdownload --keywords $searchword --format $form --limit $lim --output_directory $directory\n",
    "    src_path = directory + searchword\n",
    "    dst_train_path = directory + \"train/\"\n",
    "    dst_valid_path = directory + \"valid/\"\n",
    "    counter = 1\n",
    "    if not os.path.isdir(dst_train_path + searchword and dst_valid_path + searchword):\n",
    "        train_search_folder = dst_train_path + searchword\n",
    "        valid_search_folder = dst_valid_path + searchword\n",
    "        print(train_search_folder)\n",
    "        ! mkdir $train_search_folder\n",
    "        ! mkdir $valid_search_folder\n",
    "    for file in os.listdir(src_path):\n",
    "        src = src_path + \"/\" + file\n",
    "        dst_end = searchword + \"/\" + searchword + \".\" + str(counter) + \".\" + form\n",
    "        train_ratio = lim*0.8 \n",
    "        if(counter <= train_ratio):\n",
    "            dst = dst_train_path + dst_end\n",
    "        else:\n",
    "            dst = dst_valid_path + dst_end\n",
    "        os.rename(src, dst)\n",
    "        counter = counter + 1\n",
    "    delete_dir = directory + searchword\n",
    "    ! rm -rf $delete_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Item no.: 1 --> Item name = Female_face\n",
      "Evaluating...\n",
      "Starting Download...\n",
      "Completed Image ====> 1. archetypal-female-_3249633c.jpg\n",
      "Completed Image ====> 2. w_sexy_gr.jpg\n",
      "Completed Image ====> 3. f5a0626a80fe6026c0ac65cdc2d8ede2--photography-portraits-photography-people.jpg\n",
      "Completed Image ====> 4. stock-photo-beauty-face-of-the-young-beautiful-woman-isolated-on-white-gorgeous-female-portrait-with-slicked-723534274.jpg\n",
      "Completed Image ====> 5. 2a611d612fe22e2870394224210c310b--brown-auburn-hair-people-with-green-eyes.jpg\n",
      "Completed Image ====> 6. 9b71c869b0deb10121858118e381edea.jpg\n",
      "Completed Image ====> 7. this-survey-shows-us-how-different-men-and-women-view-the-perfect-female-face-.jpg\n",
      "Completed Image ====> 8. 9354-close-up-female-face.jpg\n",
      "Completed Image ====> 9. dzzbx.jpg\n",
      "Completed Image ====> 10. 10805-close-up-female-face.jpg\n",
      "\n",
      "Everything downloaded!\n",
      "Total Errors: 0\n",
      "\n",
      "Total time taken: 11.916243553161621 Seconds\n",
      "data/train/Female_face\n",
      "\n",
      "Item no.: 1 --> Item name = Male_face\n",
      "Evaluating...\n",
      "Starting Download...\n",
      "Completed Image ====> 1. 5237c58f-4104-456d-b6d9-c2570d823d5f.jpg\n",
      "Completed Image ====> 2. b826ccd4cbbb2853515c89fa9731da16--mens-short-hairstyles--short-natural-hairstyles.jpg\n",
      "Completed Image ====> 3. hqdefault.jpg\n",
      "Completed Image ====> 4. archetypal-male-face-of-beauty-embargoed-to-00.01hrs-30.03.15.jpg\n",
      "Completed Image ====> 5. m_sexy_gr.jpg\n",
      "Completed Image ====> 6. ff979fc66dcb9cfb401cf2d5ccbdf295--golden-eyes-male-faces.jpg\n",
      "Completed Image ====> 7. male-treatments.jpg\n",
      "Completed Image ====> 8. texturingxyz_male12_albedo_grande.jpg\n",
      "Completed Image ====> 9. f91c6368508fb15aeb64bf395ce3a456.jpg\n",
      "Completed Image ====> 10. 51bde472.jpg\n",
      "\n",
      "Everything downloaded!\n",
      "Total Errors: 0\n",
      "\n",
      "Total time taken: 8.092396974563599 Seconds\n",
      "data/train/Male_face\n"
     ]
    }
   ],
   "source": [
    "download_pictures(\"Female_face\", lim=10)\n",
    "download_pictures(\"Male_face\", lim=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizing a resizing method from FastAi - includes augmentation (side_on) and zooming \n",
    "    - Have the possibility of speeding up the training (smaller pictures) in the start\n",
    "    - bs = 64 is usually preferred until Cuda-Out-Of-Memory Exception "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['valid', 'train']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "PATH = \"data/\"\n",
    "os.listdir(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Male_face', 'Female_face']\n",
      "['Male_face', 'Female_face']\n"
     ]
    }
   ],
   "source": [
    "train_path = \"train/\"\n",
    "valid_path = \"valid/\"\n",
    "print(os.listdir(PATH + train_path))\n",
    "print(os.listdir(PATH + valid_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible to get a nicer output of the items in directories? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training folder: \n",
      "Class1:  ['Male_face.1.jpg', 'Male_face.8.jpg']\n",
      "Class2:  ['Female_face.6.jpg', 'Female_face.4.jpg']\n",
      "Validation folder: \n",
      "Class1:  ['Male_face.10.jpg', 'Male_face.9.jpg']\n",
      "Class2:  ['Female_face.9.jpg', 'Female_face.10.jpg']\n"
     ]
    }
   ],
   "source": [
    "class1_path = \"Male_face/\"\n",
    "class2_path = \"Female_face/\"\n",
    "print(\"Training folder: \")\n",
    "print(\"Class1: \" , os.listdir(PATH + train_path + class1_path)[:2])\n",
    "print(\"Class2: \" , os.listdir(PATH + train_path + class2_path)[:2])\n",
    "\n",
    "print(\"Validation folder: \")\n",
    "print(\"Class1: \" , os.listdir(PATH + valid_path + class1_path)[:2])\n",
    "print(\"Class2: \" , os.listdir(PATH + valid_path + class2_path)[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics \n",
    "\n",
    "def get_data(sz, bs):\n",
    "   tfms = tfms_from_model(arch, sz, aug_tfms=transforms_side_on, max_zoom=1.1)\n",
    "   data = ImageClassifierData.from_paths(PATH, tfms=tfms, bs=bs)\n",
    "   return data if sz > 300 else data.resize(340, 'tmp');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = resnet50\n",
    "sz = 299 # One of two standards for ImageNet (224)\n",
    "bs = 64\n",
    "\n",
    "data = get_data(sz, bs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

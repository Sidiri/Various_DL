{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "    - Find a way to import modules using (relative) path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.imports import *\n",
    "\n",
    "from fastai.transforms import *\n",
    "from fastai.conv_learner import *\n",
    "from fastai.model import *\n",
    "from fastai.dataset import *\n",
    "from fastai.sgdr import *\n",
    "from fastai.plots import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastai = \"../../FastAi/fastai\"\n",
    "fastai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir(fastai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../../FastAi/fastai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "> Download the pictures in notebook <br>\n",
    ">> Use Keras folder structure with \"train\", \"valid\", \"train/class1\", ... \n",
    "<br> <br>\n",
    ">> Rename the pictures <cr>\n",
    "    \n",
    "> Refactor the methods "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading the images\n",
    "\n",
    "Downloading the images using a program from https://github.com/hardikvasa/google-images-download and running it through bash scripting locally in the notebook. More possible configurations, such as multiple searchwords, different combinations, etc., but this is enough for now. \n",
    "\n",
    "To run this method:\n",
    "> Using pip\n",
    "> <div class=\"alert alert-block alert-info\">\n",
    "\\$ pip install google_images_download\n",
    "</div> <br>\n",
    "> Manually using CLI\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "> \\$ git clone https://github.com/hardikvasa/google-images-download.git <br>\n",
    "> \\$ cd google-images-download && sudo python setup.py install\n",
    "</div> <br>\n",
    "> Manually using UI\n",
    "> <div class=\"alert alert-block alert-info\">\n",
    "> Go to the repo on github ==> Click on *Clone or Download* ==> Click on *Download ZIP* and save it on your local disk. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The specified searchword will be a class, which in this case will be *female_face* and *male_face* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_pictures(searchword, form=\"jpg\", lim=100, directory=\"data/\"):\n",
    "    ! googleimagesdownload --keywords $searchword --format $form --limit $lim --output_directory $directory\n",
    "    src_path = directory + searchword\n",
    "    dst_train_path = directory + \"train/\"\n",
    "    dst_valid_path = directory + \"valid/\"\n",
    "    counter = 1\n",
    "    if not os.path.isdir(dst_train_path + searchword and dst_valid_path + searchword):\n",
    "        train_search_folder = dst_train_path + searchword\n",
    "        valid_search_folder = dst_valid_path + searchword\n",
    "        print(train_search_folder)\n",
    "        ! mkdir $train_search_folder\n",
    "        ! mkdir $valid_search_folder\n",
    "    for file in os.listdir(src_path):\n",
    "        src = src_path + \"/\" + file\n",
    "        dst_end = searchword + \"/\" + searchword + \".\" + str(counter) + \".\" + form\n",
    "        train_ratio = lim*0.8 \n",
    "        if(counter <= train_ratio):\n",
    "            dst = dst_train_path + dst_end\n",
    "        else:\n",
    "            dst = dst_valid_path + dst_end\n",
    "        os.rename(src, dst)\n",
    "        counter = counter + 1\n",
    "    delete_dir = directory + searchword\n",
    "    ! rm -rf $delete_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_pictures(\"Female_face\", lim=10)\n",
    "download_pictures(\"Male_face\", lim=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizing a resizing method from FastAi - includes augmentation (side_on) and zooming \n",
    "    - Have the possibility of speeding up the training (smaller pictures) in the start\n",
    "    - bs = 64 is usually preferred until Cuda-Out-Of-Memory Exception "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "PATH = \"data/\"\n",
    "os.listdir(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"train/\"\n",
    "valid_path = \"valid/\"\n",
    "print(os.listdir(PATH + train_path))\n",
    "print(os.listdir(PATH + valid_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible to get a nicer output of the items in directories? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class1_path = \"Male_face/\"\n",
    "class2_path = \"Female_face/\"\n",
    "print(\"Training folder: \")\n",
    "print(\"Class1: \" , os.listdir(PATH + train_path + class1_path)[:2])\n",
    "print(\"Class2: \" , os.listdir(PATH + train_path + class2_path)[:2])\n",
    "\n",
    "print(\"Validation folder: \")\n",
    "print(\"Class1: \" , os.listdir(PATH + valid_path + class1_path)[:2])\n",
    "print(\"Class2: \" , os.listdir(PATH + valid_path + class2_path)[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(f'{PATH}{train_path}{class1_path}')[:1]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = plt.imread(f'{PATH}{train_path}{class1_path}{files[0]}')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[:4, :4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncomment if needing to resize images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn import metrics \n",
    "\n",
    "#def get_data(sz, bs):\n",
    "#   tfms = tfms_from_model(arch, sz, aug_tfms=transforms_side_on, max_zoom=1.1)\n",
    "#   data = ImageClassifierData.from_paths(PATH, tfms=tfms, bs=bs)\n",
    "#   return data if sz > 300 else data.resize(340, 'tmp');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = resnet50\n",
    "sz = 299 # One of two standards for ImageNet (224)\n",
    "bs = 32 # 64 resulted in cuda-out-of-memory-error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = tfms_from_model(arch, sz, aug_tfms=transforms_side_on, max_zoom=1.1)\n",
    "data = ImageClassifierData.from_paths(PATH, tfms=tfms, bs=bs, num_workers=4)\n",
    "learn = ConvLearner.pretrained(arch, data, ps=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing a Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems because of non-valid image types\n",
    "\n",
    "> <div class=\"alert alert-block alert-info\">\n",
    "Can use module *imghdr* to verify image types\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imghdr\n",
    "imghdr.what(f'{PATH}{train_path}{class1_path}{files[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need to loop through datasets to remove invalid images \n",
    "\n",
    "> <div class=\"alert alert-block alert-info\">\n",
    "But first, interesting to see how much data we will be losing:\n",
    "</div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class1_train = PATH + train_path + class1_path\n",
    "class2_train = PATH + train_path + class2_path\n",
    "class1_valid = PATH + valid_path + class1_path\n",
    "class2_valid = PATH + valid_path + class2_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(class1_path[:-1] + \" training files: \" , len(os.listdir(PATH + train_path + class1_path)))\n",
    "print(class2_path[:-1] + \" training files: \" , len(os.listdir(PATH + train_path + class2_path)))\n",
    "print(class1_path[:-1] + \" validation files: \" , len(os.listdir(PATH + valid_path + class1_path)))\n",
    "print(class2_path[:-1] + \" validation files: \" , len(os.listdir(PATH + valid_path + class2_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [class1_train, \n",
    "              class2_train, \n",
    "              class1_valid, \n",
    "              class2_valid]\n",
    "for path in file_paths:\n",
    "    for files in os.listdir(path):\n",
    "        if imghdr.what(path + files) != 'jpeg':\n",
    "            os.remove(path + files)\n",
    "            print(\"Deleting \" + files + \" in folder \" + path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(class1_path[:-1] + \" training files: \" , len(os.listdir(PATH + train_path + class1_path)))\n",
    "print(class2_path[:-1] + \" training files: \" , len(os.listdir(PATH + train_path + class2_path)))\n",
    "print(class1_path[:-1] + \" validation files: \" , len(os.listdir(PATH + valid_path + class1_path)))\n",
    "print(class2_path[:-1] + \" validation files: \" , len(os.listdir(PATH + valid_path + class2_path)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New data set, so new training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = tfms_from_model(arch, sz, aug_tfms=transforms_side_on, max_zoom=1.1)\n",
    "data = ImageClassifierData.from_paths(PATH, tfms=tfms, bs=bs, num_workers=4)\n",
    "learn = ConvLearner.pretrained(arch, data, ps=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(1e-2, 2, cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "lr = np.array([1e-4, 1e-3, 1e-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lr, 3, cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_preds, y = learn.TTA()\n",
    "probs = np.mean(np.exp(log_preds), 0)\n",
    "\n",
    "accuracy_np(probs, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting\n",
    "\n",
    "### When validation loss >> training \n",
    "\n",
    "> <div class=\"alert alert-block alert-info\">\n",
    "Increase dropout, unfreeze and using differential learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ConvLearner.pretrained(arch, data, ps=0.5)\n",
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lr, 3, cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_preds, y = learn.TTA()\n",
    "probs = np.mean(np.exp(log_preds), 0)\n",
    "\n",
    "accuracy_np(probs, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.argmax(probs, axis=1)\n",
    "probs = probs[:,1]\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm, data.classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

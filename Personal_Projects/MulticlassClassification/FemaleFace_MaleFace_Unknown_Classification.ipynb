{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">\n",
    "A model that can distinguish between female and male faces - if neither it is labeled \"Unknown\" (referred to as \"Image\")\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE: The comments in this notebook comes from training using ~1000 images of each label, so if one gets different results, even with the same amount of images that is to be expected. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"../../FastAi\")\n",
    "# Only necessary when running both ROS and fast.ai at the same computer\n",
    "#sys.path.remove('/opt/ros/kinetic/lib/python2.7/dist-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (os.listdir(\"../../FastAi\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.imports import *\n",
    "\n",
    "from fastai.transforms import *\n",
    "from fastai.conv_learner import *\n",
    "from fastai.model import *\n",
    "from fastai.dataset import *\n",
    "from fastai.sgdr import *\n",
    "from fastai.plots import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the images\n",
    "\n",
    "Downloading the images using a program from https://github.com/hardikvasa/google-images-download and running it through bash scripting locally in the notebook. More possible configurations, such as multiple searchwords, different combinations, etc., but this is enough for now. \n",
    "\n",
    "To run this method: <br>\n",
    "#### Using pip\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "$ pip install google_images_download\n",
    "</div> <br>\n",
    " Manually using CLI\n",
    " <div class=\"alert alert-block alert-info\">\n",
    " \\$ git clone https://github.com/hardikvasa/google-images-download.git <br>\n",
    " \\$ cd google-images-download && sudo python setup.py install\n",
    " </div> <br>  \n",
    " Manually using UI\n",
    " <div class=\"alert alert-block alert-info\">\n",
    "Go to the repo on github ==> Click on *Clone or Download* ==> Click on *Download ZIP* and save it on your local disk. </div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "**NOTE** To download > 100 images, please see GitHub <br>\n",
    "Involves downloading Chromedriver <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The specified searchwords will be the classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing the data in such a way that it matches standard PyTorch folder setup\n",
    "> <div class=\"alert alert-block alert-info\">\n",
    "*data/train/className* <br />\n",
    "*data/valid/className*\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If error messages on chromedriver (downloading > 100 images), try downloading a different version \n",
    "```http://chromedriver.chromium.org/downloads) ```\n",
    "\n",
    "#### Or verify that the path to the executable is correct\n",
    "Tip is to use ```os.listdir()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromedriver_path = \"../../chromedriver_win32/chromedriver\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If one has a valid chromedriver (path), add \n",
    "```--chromedriver $chromedriver_path```\n",
    "\n",
    "at the end of \n",
    "\n",
    "```! googleimagesdownload --keywords $searchword --format $form --limit $lim --output_directory $directory```\n",
    "\n",
    "### Or copy this line:\n",
    "\n",
    "```! googleimagesdownload --keywords $searchword --format $form --limit $lim --output_directory $directory --chromedriver $chromedriver_path```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_images(searchword, form=\"jpg\", lim=100, directory= \"data\"):\n",
    "    if not os.path.isdir(directory):\n",
    "        ! mkdir $directory\n",
    "    ! googleimagesdownload --keywords $searchword --format $form --limit $lim --output_directory $directory \n",
    "    src_path = os.path.join(directory, searchword)\n",
    "    if not os.path.isdir(src_path):\n",
    "        ! mkdir $src_path\n",
    "    dst_train_path = os.path.join(directory, \"train\")\n",
    "    dst_valid_path = os.path.join(directory, \"valid\")\n",
    "    if not os.path.isdir(dst_train_path and dst_valid_path):\n",
    "        ! mkdir $dst_train_path\n",
    "        ! mkdir $dst_valid_path\n",
    "    train_search_folder = os.path.join(dst_train_path, searchword)\n",
    "    valid_search_folder = os.path.join(dst_valid_path, searchword)\n",
    "    if not os.path.isdir(train_search_folder and valid_search_folder):\n",
    "        ! mkdir $train_search_folder\n",
    "        ! mkdir $valid_search_folder\n",
    "    counter = 0\n",
    "    number_of_files = len(os.listdir(src_path))\n",
    "    train_ratio = number_of_files*0.7 \n",
    "    for file in os.listdir(src_path):\n",
    "        src = os.path.join(src_path, file)\n",
    "        end = (searchword + \".\" + str(counter) + \".\" + form)\n",
    "        dst_end = os.path.join(searchword, end)\n",
    "        if(counter <= train_ratio):\n",
    "            dst = os.path.join(dst_train_path, dst_end)\n",
    "        else:\n",
    "            dst = os.path.join(dst_valid_path, dst_end)\n",
    "        os.replace(src, dst)\n",
    "        counter = counter + 1\n",
    "    delete_dir = os.path.join(directory, searchword)\n",
    "    ! rmdir /s /q $delete_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying the desired classes to classify\n",
    "Because of how the image downloader is set up the word *Image* is used instead of *Unknown*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class1_name = \"Female_face\"\n",
    "class2_name = \"Male_face\"\n",
    "class3_name = \"Image\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "download_images(class1_name, lim=10);\n",
    "download_images(class2_name, lim=10);\n",
    "download_images(class3_name, lim=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "> Utilizing the FastAi framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the necessary PATH to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"data\"\n",
    "os.listdir(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(PATH, \"train\")\n",
    "valid_path = os.path.join(PATH, \"valid\")\n",
    "print(os.listdir(train_path))\n",
    "print(os.listdir(valid_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible to get a nicer output of the items in directories? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class1_path_train = os.path.join(train_path, class1_name)\n",
    "class2_path_train = os.path.join(train_path, class2_name)\n",
    "class3_path_train = os.path.join(train_path, class3_name)\n",
    "\n",
    "class1_path_valid = os.path.join(valid_path, class1_name)\n",
    "class2_path_valid = os.path.join(valid_path, class2_name)\n",
    "class3_path_valid = os.path.join(valid_path, class3_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Training folder: \")\n",
    "print(\"Class1: \" , os.listdir(class1_path_train)[:2])\n",
    "print(\"Class2: \" , os.listdir(class2_path_train)[:2])\n",
    "print(\"Class3: \" , os.listdir(class3_path_train)[:2])\n",
    "\n",
    "print(\"Validation folder: \")\n",
    "print(\"Class1: \" , os.listdir(class1_path_valid)[:2])\n",
    "print(\"Class2: \" , os.listdir(class2_path_valid)[:2])\n",
    "print(\"Class3: \" , os.listdir(class3_path_valid)[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.listdir(class2_path_train)[:1]\n",
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_file_path = os.path.join(class2_path_train, file[0])\n",
    "img = plt.imread(full_file_path)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[:4, :4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncomment if needing to resize images \n",
    "\n",
    "> <div class=\"alert alert-block alert-warning\">\n",
    "Possible problems with it storing them in *tmp* folder\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn import metrics \n",
    "#\n",
    "#def get_data(sz, bs):\n",
    "#    tfms = tfms_from_model(arch, sz, aug_tfms=transforms_side_on, max_zoom=1.1)\n",
    "#    data = ImageClassifierData.from_paths(PATH, tfms=tfms, bs=bs)\n",
    "#    return data if sz > 300 else data.resize(340, 'tmp');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting training values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = resnet34\n",
    "sz = 299 # One of two standards for ImageNet (224)\n",
    "bs = 64 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation\n",
    "When training for multiple epochs, the model will start overfitting, which basically means the model is learning to recognizing specific images in the training set, rather than generalizing such that it is relevant for other images than just the ones in the training set. \n",
    "\n",
    "One quick fix is to effectively create more data, through data augmentation. This refers to randomly changing the images in ways that shouldn't impact their interpretation, such as horizontal flipping, zooming, and rotating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation = transforms_side_on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "tfms = tfms_from_model(arch, sz, aug_tfms=augmentation, max_zoom=1.1)\n",
    "data = ImageClassifierData.from_paths(PATH, tfms=tfms, bs=bs, num_workers=1)\n",
    "learn = ConvLearner.pretrained(arch, data, ps=0.4)\n",
    "learn.fit(1e-3, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems because of non-valid image types\n",
    "\n",
    "> <div class=\"alert alert-block alert-info\">\n",
    "Can use module *imghdr* to verify image types\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imghdr\n",
    "imghdr.what(full_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through dataset to remove invalid images \n",
    "\n",
    "> <div class=\"alert alert-block alert-info\">\n",
    "But first, interesting to see amount of lost data\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(class1_name + \" training files: \" , len(os.listdir(class1_path_train)))\n",
    "print(class2_name + \" training files: \" , len(os.listdir(class2_path_train)))\n",
    "print(class3_name + \" training files: \" , len(os.listdir(class3_path_train)))\n",
    "print(class1_name + \" validation files: \" , len(os.listdir(class1_path_valid)))\n",
    "print(class2_name + \" validation files: \" , len(os.listdir(class2_path_valid)))\n",
    "print(class3_name + \" validation files: \" , len(os.listdir(class3_path_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [class1_path_train, \n",
    "              class2_path_train,\n",
    "              class3_path_train,\n",
    "              class1_path_valid, \n",
    "              class2_path_valid,\n",
    "            class3_path_valid]\n",
    "for path in file_paths:\n",
    "    for files in os.listdir(path):\n",
    "        file_path = os.path.join(path, files)\n",
    "        if imghdr.what(file_path) != 'jpeg':\n",
    "            os.remove(file_path);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(class1_name + \" training files: \" , len(os.listdir(class1_path_train)))\n",
    "print(class2_name + \" training files: \" , len(os.listdir(class2_path_train)))\n",
    "print(class3_name + \" training files: \" , len(os.listdir(class3_path_train)))\n",
    "print(class1_name + \" validation files: \" , len(os.listdir(class1_path_valid)))\n",
    "print(class2_name + \" validation files: \" , len(os.listdir(class2_path_valid)))\n",
    "print(class3_name + \" validation files: \" , len(os.listdir(class3_path_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: Tried to switch image type from *None* to *JPEG* \n",
    "> <div class=\"alert alert-block alert-info\">\n",
    "In order to minimize data loss. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updated data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ImageClassifierData.from_paths(PATH, tfms=tfms, bs=bs, num_workers=4)\n",
    "learn = ConvLearner.pretrained(arch, data, ps=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.fit(1e-2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(1e-2, 3, cycle_len=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locate optimal learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal learning rate is slightly lower than 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lr, 3, cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Unfreezing the first layers, and checking if there is a new optimal learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.lr_find()\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lr, 4, cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking accuracy on validation set using _Test Time Augmentation_\n",
    "Using the same transforms method as specified *tfms*, which provides the model with 4 additional images. \n",
    "\n",
    "The model uses these 5 images (4 transforms, 1 original) and outputs the average classification between these 5 images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_preds, y = learn.TTA()\n",
    "probs = np.mean(np.exp(log_preds), 0)\n",
    "\n",
    "accuracy_np(probs, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(\"Resnet34_multiclass\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Data Augmentation\n",
    "When training for multiple epochs, the model will start overfitting, which basically means the model is learning to recognizing specific images in the training set, rather than generalizing such that it is relevant for other images than just the ones in the training set. \n",
    "\n",
    "One quick fix is to effectively create more data, through data augmentation. This refers to randomly changing the images in ways that shouldn't impact their interpretation, such as horizontal flipping, zooming, and rotating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_augs():\n",
    "    data = ImageClassifierData.from_paths(PATH, bs=2, tfms=tfms, num_workers=1)\n",
    "    x,_ = next(iter(data.aug_dl))\n",
    "    return data.trn_ds.denorm(x)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ims = np.stack([get_augs() for i in range(6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots(ims, rows=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can se that the model is *overfitting*\n",
    "\n",
    "### When *validation loss* >> *training* \n",
    "\n",
    "> <div class=\"alert alert-block alert-info\">\n",
    "Possible solutions: Data Augmentation, Increase dropout, unfreeze and use differential learning rates\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not very good results: 82% accuracy and overfitting\n",
    "\n",
    "### Initially: increase dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ConvLearner.pretrained(arch, data, ps=0.65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(1e-2, 3, cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Nothing interesting. <br>\n",
    "> Trying to unfreeze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(1e-3, 3, cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Again using _Test Time Augmentation_ to improve the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_preds, y = learn.TTA()\n",
    "probs = np.mean(np.exp(log_preds), 0)\n",
    "\n",
    "accuracy_np(probs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(\"Resnet34_multiclass\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "> ### Suboptimal, but considering the data set it's all one can expect\n",
    "\n",
    "Though, interesting to see if a more powerful model will have an impact\n",
    "## Trying with a different model: *Resnext50*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = resnext50\n",
    "sz = 299 # One of two standards for ImageNet (224)\n",
    "bs = 32 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = tfms_from_model(arch, sz, aug_tfms=transforms_side_on, max_zoom=1.1)\n",
    "data = ImageClassifierData.from_paths(PATH, tfms=tfms, bs=bs, num_workers=4)\n",
    "learn = ConvLearner.pretrained(arch, data, ps=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(1e-3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> No clear optimal learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(1e-4, 2, cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Again, no clear cut optimal learning rate, but seems that 1e-2 is the best choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lr, 3, cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(\"ResNext50_multiclass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_preds,y = learn.TTA()\n",
    "probs = np.mean(np.exp(log_preds),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_np(probs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.argmax(probs, axis=1)\n",
    "probs = probs[:,1]\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm, data.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "> ## 83,4 % accuracy is sligthly better than what Resnet34 gave us\n",
    "> ### Considering the data set the result is not too bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
